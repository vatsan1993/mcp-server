{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec59222e",
   "metadata": {},
   "source": [
    "![image](imgs/image1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31549972",
   "metadata": {},
   "source": [
    "- MCP (Model Context Protocol) is an open-source standard for connecting AI applications to external systems.\n",
    "- Using MCP, AI applications like Claude or ChatGPT can connect to data sources (e.g. local files, databases), tools (e.g. search engines, calculators) and workflows (e.g. specialized prompts)â€”enabling them to access key information and perform tasks.\n",
    "- Think of MCP like a USB-C port for AI applications. Just as USB-C provides a standardized way to connect electronic devices, MCP provides a standardized way to connect AI applications to external systems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6568c25f",
   "metadata": {},
   "source": [
    "![image](imgs/image2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07a059a",
   "metadata": {},
   "source": [
    "![image](imgs/image3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8fb0b2",
   "metadata": {},
   "source": [
    "- So instead of binding the tool directly to the llms, we can setup an MCP server which handles all the tools.\n",
    "- Now for this to work all the tools needs to adhere to the MCP protocol."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839b2451",
   "metadata": {},
   "source": [
    "![image](imgs/image4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69cf7893",
   "metadata": {},
   "source": [
    "Main components:\n",
    "\n",
    "MCP Client\n",
    "\n",
    "- Usually the LLM application (e.g., an AI agent)\n",
    "\n",
    "- Sends requests for tools, data, or actions\n",
    "\n",
    "MCP Server\n",
    "\n",
    "- Exposes capabilities (tools, APIs, data sources)\n",
    "\n",
    "- Responds to client requests\n",
    "\n",
    "Tools\n",
    "\n",
    "- Callable functions (e.g., search, DB query, file access)\n",
    "\n",
    "- Defined with schemas so the model knows how to use them\n",
    "\n",
    "Resources\n",
    "\n",
    "- Read-only or structured data (files, docs, DB records, APIs)\n",
    "\n",
    "Prompts\n",
    "\n",
    "- Predefined prompt templates or instructions\n",
    "\n",
    "- Help guide model behavior consistently\n",
    "\n",
    "Transport Layer\n",
    "\n",
    "- How client and server communicate (stdio, HTTP, WebSocket)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd789a5",
   "metadata": {},
   "source": [
    "#### The MCP Server and the services will be managed by the tool Providers.\n",
    "- if there is any updates in the tool, the tool provider will handle the updates. we dont need to update the integration in our app.\n",
    "- the decoupling helps quite a lot.\n",
    "- in the notmal AI that we developed, we need to update the code to match the tool updates. for example, parameter lists, or even package change and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8471a080",
   "metadata": {},
   "source": [
    "![image](imgs/image5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8278b2",
   "metadata": {},
   "source": [
    "- when a question is asked, the MCP client will request the MCP server to send the available tools. \n",
    "- the MCP server will send the available tools to the MCP client. \n",
    "- the MCP client will send this as a context to the LLM. \n",
    "- the LLM will generate a plan based on the available tools. \n",
    "- the MCP client will request the tool execution by sending another request to the MCP server.\n",
    "- the MCP server will execute the tool and send the result back to the MCP client.\n",
    "- the MCP client will send this result(context) back to the LLM.\n",
    "- the LLM then shows the final result to the user.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b6d93d",
   "metadata": {},
   "source": [
    "![image](imgs/image6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f163ad",
   "metadata": {},
   "source": [
    "- To make a mcp tool we need to use @mcp.tool decorator to define the tools that we want to use.\n",
    "- To make a mcp resource we need to use @mcp.resource decorator to define the resources that we want to use.\n",
    "- mcp tool lets llms to take action through your server. does some computation an gives side effects\n",
    "- mcp resource is used to expose tools to llms. they are essentially rest apis endpoints.\n",
    "- prompts are reusable templates that help LLMs interact with tyour server effectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9835ec98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7d81f48e",
   "metadata": {},
   "source": [
    "- we can use different apps to work has mcp host.\n",
    "- to run the server we need to use the following command\n",
    "```python\n",
    "uv run mcp dev server/weather.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69073cf2",
   "metadata": {},
   "source": [
    "# running in claude desktop.\n",
    "uv run mcp install server/weather.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc27e30",
   "metadata": {},
   "source": [
    "# to run the app that connect to the mcp, we need to run the client\n",
    "\n",
    "<code>\n",
    "uv run server/client.py\n",
    "</code>\n",
    "\n",
    "the client app uses a package called mcp-use\n",
    "It has MCPClient class that we can use to connect to the mcp server\n",
    "It has MCPAgent class that allows our llm to connect to the client."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef3549b",
   "metadata": {},
   "source": [
    "# the dockerized app is in the mcpserver folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462134ee",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
